#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script ƒë·ªÉ ingest T·∫§T C·∫¢ symbols NHANH v·ªõi batch embeddings + parallel processing

OPTIMIZATIONS:
- Batch embeddings (50-100x faster than single embeddings)
- Parallel symbol processing (v·ªõi rate limiting)
- Skip symbols without data
- Progress tracking

Usage:
    python ingest_all_symbols_fast.py
    python ingest_all_symbols_fast.py --limit 10  # Test v·ªõi 10 symbols
    python ingest_all_symbols_fast.py --workers 3  # Process 3 symbols in parallel
    python ingest_all_symbols_fast.py --batch-size 100  # Larger batch size
"""

import sys
import time
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
from vnstock_data import Listing
from ingest_financial_data import ingest_to_qdrant
from config import Config

def main():
    parser = argparse.ArgumentParser(description='Fast ingest all stock symbols to Qdrant')
    parser.add_argument('--limit', type=int, default=None, 
                       help='Limit number of symbols to process (for testing)')
    parser.add_argument('--start-from', type=int, default=0,
                       help='Start from index (useful for resuming)')
    parser.add_argument('--workers', type=int, default=1,
                       help='Number of parallel symbol workers (default: 1, max: 5 recommended)')
    parser.add_argument('--skip-errors', action='store_true',
                       help='Continue processing even if a symbol fails')
    parser.add_argument('--force', action='store_true',
                       help='Skip confirmation prompt for high worker counts')
    
    args = parser.parse_args()
    
    # Validate workers
    if args.workers > 5 and not args.force:
        print(f"‚ö†Ô∏è  Warning: {args.workers} workers may cause rate limiting. Recommended max: 5")
        response = input("Continue? (y/n): ")
        if response.lower() != 'y':
            sys.exit(0)
    
    print("=" * 60)
    print("üöÄ FAST INGESTING ALL STOCK SYMBOLS")
    print("=" * 60)
    
    # L·∫•y t·∫•t c·∫£ symbols
    print("\nüìã ƒêang l·∫•y danh s√°ch t·∫•t c·∫£ m√£ ch·ª©ng kho√°n t·ª´ VNStock...")
    try:
        listing = Listing(source='VCI')
        df = listing.all_symbols()
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y danh s√°ch symbols: {e}")
        sys.exit(1)
    
    # L·ªçc l·∫•y c·ªôt ticker
    if 'ticker' in df.columns:
        all_tickers = df['ticker'].tolist()
    elif 'symbol' in df.columns:
        all_tickers = df['symbol'].tolist()
    else:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt ticker/symbol. C√°c c·ªôt c√≥ s·∫µn: {df.columns.tolist()}")
        sys.exit(1)
    
    # L·ªçc b·ªè gi√° tr·ªã NaN/None
    all_tickers = [str(t).upper() for t in all_tickers if t and str(t).strip()]
    
    print(f"‚úÖ T√¨m th·∫•y {len(all_tickers)} m√£ ch·ª©ng kho√°n")
    
    # Apply filters
    start_idx = args.start_from
    end_idx = min(start_idx + args.limit, len(all_tickers)) if args.limit else len(all_tickers)
    tickers = all_tickers[start_idx:end_idx]
    
    print(f"\nüéØ S·∫Ω x·ª≠ l√Ω {len(tickers)} m√£ (t·ª´ index {start_idx} ƒë·∫øn {end_idx-1})")
    print(f"üîß Qdrant: {Config.QDRANT_HOST}")
    print(f"üì¶ Collection: {Config.QDRANT_COLLECTION}")
    print(f"‚ö° Workers: {args.workers} symbols in parallel")
    print(f"üõ°Ô∏è  Skip errors: {args.skip_errors}")
    print(f"üí° Batch embeddings: ENABLED (50-100x faster!)")
    
    # Statistics
    success_count = 0
    error_count = 0
    error_symbols = []
    lock = Lock()
    
    start_time = time.time()
    
    # Process function for each ticker
    def process_ticker(i, ticker):
        nonlocal success_count, error_count
        ticker = str(ticker).upper()
        
        print(f"\n{'='*60}")
        print(f"[{i+1}/{end_idx}] Processing {ticker}")
        print(f"{'='*60}")
        
        try:
            # First ticker: recreate collection, rest: add to collection
            recreate = (i == start_idx)
            ingest_to_qdrant(ticker, recreate_collection=recreate)
            
            with lock:
                success_count += 1
            
            print(f"‚úÖ Th√†nh c√¥ng: {ticker}")
            return (ticker, True, None)
            
        except Exception as e:
            with lock:
                error_count += 1
            
            error_msg = str(e)
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω {ticker}: {error_msg}")
            return (ticker, False, error_msg)
    
    # Process with ThreadPoolExecutor
    if args.workers > 1:
        print(f"\nüöÄ Ch·∫°y parallel v·ªõi {args.workers} workers...")
        with ThreadPoolExecutor(max_workers=args.workers) as executor:
            futures = {
                executor.submit(process_ticker, start_idx + idx, ticker): ticker 
                for idx, ticker in enumerate(tickers)
            }
            
            for future in as_completed(futures):
                ticker, success, error = future.result()
                
                if not success:
                    error_symbols.append(ticker)
                    if not args.skip_errors:
                        print(f"\n‚ö†Ô∏è  D·ª´ng x·ª≠ l√Ω do g·∫∑p l·ªói. ƒê·ªÉ ti·∫øp t·ª•c b·ªè qua l·ªói, d√πng --skip-errors")
                        # Cancel remaining futures
                        for f in futures:
                            f.cancel()
                        break
    else:
        # Sequential processing
        print(f"\nüîÑ Ch·∫°y tu·∫ßn t·ª± (1 symbol m·ªói l·∫ßn)...")
        for idx, ticker in enumerate(tickers):
            ticker_result = process_ticker(start_idx + idx, ticker)
            ticker, success, error = ticker_result
            
            if not success:
                error_symbols.append(ticker)
                if not args.skip_errors:
                    print(f"\n‚ö†Ô∏è  D·ª´ng x·ª≠ l√Ω do g·∫∑p l·ªói. ƒê·ªÉ ti·∫øp t·ª•c b·ªè qua l·ªói, d√πng --skip-errors")
                    break
    
    # Summary
    elapsed_time = time.time() - start_time
    print("\n" + "="*60)
    print("üìä TH·ªêNG K√ä")
    print("="*60)
    print(f"‚úÖ Th√†nh c√¥ng: {success_count}/{len(tickers)} symbols")
    print(f"‚ùå Th·∫•t b·∫°i: {error_count}/{len(tickers)} symbols")
    print(f"‚è±Ô∏è  Th·ªùi gian: {elapsed_time:.2f}s ({elapsed_time/60:.2f} ph√∫t)")
    
    if success_count > 0:
        avg_time = elapsed_time / success_count
        print(f"‚ö° Trung b√¨nh: {avg_time:.2f}s/symbol")
        
        # Estimate remaining time
        remaining = len(all_tickers) - end_idx
        if remaining > 0:
            est_time = remaining * avg_time
            print(f"üìà ∆Ø·ªõc t√≠nh th·ªùi gian c√≤n l·∫°i cho {remaining} symbols: {est_time/3600:.2f} gi·ªù")
    
    if error_symbols:
        print(f"\n‚ùå C√°c symbol b·ªã l·ªói:")
        for sym in error_symbols[:20]:  # Show first 20
            print(f"   - {sym}")
        if len(error_symbols) > 20:
            print(f"   ... v√† {len(error_symbols) - 20} symbols kh√°c")
        
        print(f"\nüí° ƒê·ªÉ x·ª≠ l√Ω l·∫°i c√°c symbol b·ªã l·ªói:")
        print(f"   python ingest_financial_data.py {' '.join(error_symbols[:10])}")
    
    print("\n" + "="*60)
    if error_count == 0:
        print("‚úÖ HO√ÄN T·∫§T T·∫§T C·∫¢!")
    else:
        print("‚ö†Ô∏è  HO√ÄN T·∫§T V·ªöI M·ªòT S·ªê L·ªñI")
    print("="*60)
    
    # Performance summary
    print("\nüí° TIPS TO IMPROVE:")
    if args.workers == 1:
        print("  - TƒÉng workers: --workers 3 (x·ª≠ l√Ω 3 symbols song song)")
    if success_count > 0 and avg_time > 10:
        print("  - Th·ªùi gian trung b√¨nh c√≤n cao, ki·ªÉm tra network/API")

if __name__ == "__main__":
    main()

